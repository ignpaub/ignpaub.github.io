---
title: "QDGset: A Large Scale Grasping Dataset Generated with Quality-Diversity"
collection: publications
category: conferences
permalink: /publication/2025_icra
excerpt: ' '
date: 2025-05-24
venue: '2025 IEEE International Conference on Robotics and Automation, Atlanta (USA), 19-23 May'
paperurl: 'http://ignpaub.github.io/files/2025_icra.pdf'
citation: "Johann Huber, François Hélénon, Mathilde Kappel, Ignacio de Loyola Páez-Ubieta, Santiago T. Puente, Pablo Gil, Faïz Ben Amar, Stéphane Doncieux (2025). &quot;QDGset: A Large Scale Grasping Dataset Generated with Quality-Diversity.&quot; <i>2025 International Conference on Robotics and Automation (ICRA)</i>. doi: 10.1109/ICRA55743.2025.11127427."
---

Recent advances in AI have led to significant results in robotic learning, but skills like grasping remain partially solved. Many recent works exploit synthetic grasping datasets to learn to grasp unknown objects. However, those datasets were generated using simple grasp sampling methods using priors. Recently, Quality-Diversity (QD) algorithms have been proven to make grasp sampling significantly more efficient. In this work, we extend QDG-6DoF, a QD framework for generating object-centric grasps, to scale up the production of synthetic grasping datasets. We propose a data augmentation method that combines the transformation of object meshes with transfer learning from previous grasping repertoires. The conducted experiments show that this approach reduces the number of required evaluations per discovered robust grasp by up to 20%. We used this approach to generate QDGset, a dataset of 6DoF grasp poses that contains about 3.5 and 4.5 times more grasps and objects, respectively, than the previous state-of-the-art. Our method allows anyone to easily generate data, eventually contributing to a large-scale collaborative dataset of synthetic grasps. 

Keywords: Artificial Intelligence, Mobile Robots, Neural Networks, Instance Segmentation, LiDAR, YOLO

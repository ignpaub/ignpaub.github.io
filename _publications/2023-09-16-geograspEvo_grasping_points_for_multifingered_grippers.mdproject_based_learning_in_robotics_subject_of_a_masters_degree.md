---
title: "GeoGraspEvo: grasping points for multifingered grippers"
collection: publications
category: conferences
permalink: /publication/2023_etfa1
excerpt: ' '
date: 2023-09-16
venue: '2023 IEEE 28th International Conference on Emerging Technologies and Factory Automation (ETFA), Sinaia (Romania), 12-15 September'
paperurl: 'http://ignpaub.github.io/files/2023_etfa1.pdf'
citation: "Ignacio de Loyola Páez-Ubieta, Edison Velasco-Sánchez, Santiago T. Puente, Pablo Gil, Francisco A. Candelas. (2023). &quot;GeoGraspEvo: grasping points for multifingered grippers.&quot; <i>2023 IEEE 28th International Conference on Emerging Technologies and Factory Automation (ETFA)</i>. 1-4, doi: 10.1109/ETFA54631.2023.10275406"
---

The task of grasping objects is a simple and routinely action for humans but it is complex for robots. To integrate robots into everyday tasks, they have to be equipped with capabilities human-like dexterity. In this line, we propose an analytic method, called GeoGraspEvo, to compute grasping points to be used by robotic hands with three, four or more fingers. Our proposal uses features computed from visible surface objects captured by a single RGBD image of a scene. Additionally, it uses as input some configurable kinematic parameters to be able to carry out the grasping depending on the hand morphology. The method compute grasping points with no training process.

Keywords: Robotics, RGB-D Perception, Perception for Grasping, Manipulation Planning, Grasping points.
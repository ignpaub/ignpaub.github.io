---
title: "GeoGraspEvo: Multifinger Grasp Pose Estimation"
collection: publications
category: pending_manuscripts
#permalink: /publication/2023-10-13-vision_and_tactile_robotic_system_to_grasp_litter_in_outdoor_environments
excerpt: ' '
date: 2025-04-01
venue: 'Machine Vision and Applications (MVA)'
#slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
#paperurl: 'http://ignpaub.github.io/files/2023_jint.pdf'
citation: 'Ignacio de Loyola PÃ¡ez-Ubieta, Daniel Frau-Alfaro, Santiago Timoteo Puente (2025). &quot;GeoGraspEvo: Multifinger Grasp Pose Estimation. &quot; <i>Machine Vision and Applications (MVA)</i>. Under review'

---

Grasping objects is a simple task for humans, but transferring this ability to robots is much more complex. Traditionally, existing methods can be grouped into two separate categories: analytical and data-driven. In recent years, thanks to the increase in computing capabilities, the research community has focused its attention on the second group of algorithms. In this article, we propose a new grasping method called GeoGraspEvo. It belongs to the group of analytical methods and allows to obtain the best combination of grasping points for multi-finger grippers, starting from only three fingers. The whole procedure is explained, starting from some gripper parameters and a RGBD image, through the extraction of the gripping areas and candidates, to the developed ranking functions. Experiments are performed on a well-known dataset in both simulation and real world with a three-finger gripper to show the quality of the presented method.The results show a successful grasping rate of 91.46% in simulation and 81.46% in real world with different shaped objects with an execution time of 120 ms and 83 ms respectively. With these results, we are able to match and improve some state-of-the-art methods in accuracy and computation time in both of the aforementioned categories, just by using CPU capabilities with a generalist method, avoiding dataset generation or long GPU training times. Code is available at the project website.

Keywords: Robotics, RGB-D Perception, Perception for Grasping, Manipulation Planning, Grasping Points